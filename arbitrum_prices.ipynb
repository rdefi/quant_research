{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression vs Lasso and Ridge Regression for Arbitrum Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso regression and ridge regression are regularization techniques.\n",
    "# Regularization helps avoid overfitting by adding a penalty term to the best fit derived from the trained data,\n",
    "# to achieve a lower variance with the tested data and restrict the influence of predictor variables over the output variable\n",
    "# Shrinkage is where the data values are shrunk toward a central point as the mean.\n",
    "# Lasso and ridge regression encourage simple, sparse models (fewer parameters)\n",
    "# This type of regression is well-suited for models showing high levels of multicollinearity\n",
    "# or when you want to automate certain parts of model selection, like variable selection/parameter elimination\n",
    "\n",
    "# In Lasso regression, the cost function adds a penalty that is the absolute value of the magnitude of the coefficients\n",
    "\n",
    "# In Ridge regression, the cost function adds a penalty that is equivalent to the square of the magnitude of the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import price data for 1-minute intervals for Arbitrum, Bitcoin, Ethereum, Optimism, and Polygon\n",
    "# See if Arbitrum's price action is driven by the others\n",
    "imported_data = pd.read_csv(\"../Desktop/crypto_data_python/arb_and_comp_042823_1min.csv\")\n",
    "# print(imported_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "imported_data.rename(columns={\"open\": \"arb_open\", \"high\": \"arb_high\", \"low\": \"arb_low\", \"close\": \"arb_close\"}, inplace=True)\n",
    "imported_data.rename(columns={\"BTCUSD, BINANCE: Open\": \"btc_open\",  \"BTCUSD, BINANCE: High\": \"btc_high\", \"BTCUSD, BINANCE: Low\": \"btc_low\", \"BTCUSD, BINANCE: Close\": \"btc_close\"}, inplace=True)\n",
    "imported_data.rename(columns={\"ETHUSD, BINANCE: Open\": \"eth_open\", \"ETHUSD, BINANCE: High\": \"eth_high\", \"ETHUSD, BINANCE: Low\": \"eth_low\", \"ETHUSD, BINANCE: Close\": \"eth_close\"}, inplace=True)\n",
    "imported_data.rename(columns={\"OPUSD, BINANCE: Open\": \"op_open\", \"OPUSD, BINANCE: High\": \"op_high\", \"OPUSD, BINANCE: Low\": \"op_low\", \"OPUSD, BINANCE: Close\": \"op_close\"}, inplace=True)\n",
    "imported_data.rename(columns={\"MATICUSD, BINANCE: Open\": \"matic_open\", \"MATICUSD, BINANCE: High\": \"matic_high\", \"MATICUSD, BINANCE: Low\": \"matic_low\", \"MATICUSD, BINANCE: Close\": \"matic_close\"}, inplace=True)\n",
    "imported_data.drop(columns=[\"RSI\", \"RSI-based MA\", \"Upper Bollinger Band\", \"Lower Bollinger Band\"], inplace=True)\n",
    "imported_data[\"time\"] = pd.to_datetime(imported_data[\"time\"])\n",
    "# print(imported_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only the closing data \n",
    "# Drop all OP data because there are a lot of missing data points from Binance (and also other exchanges)\n",
    "columns_to_drop =  [\"time\", \"eth_open\", \"eth_high\", \"eth_low\", \"op_open\", \"op_high\", \"op_low\", \"op_close\", \"btc_open\", \"btc_high\", \"btc_low\", \\\n",
    "    \"arb_open\", \"arb_high\", \"arb_low\", \"matic_open\", \"matic_high\", \"matic_low\", \"MA\", \"Smoothing Line\", \"EMA\", \"Smoothing Line.1\", \"Volume\", \"Volume MA\"]\n",
    "imported_data = imported_data.drop(columns_to_drop, axis=1)\n",
    "# print(imported_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "imported_data[\"matic_close_shifted\"] = imported_data[\"matic_close\"].shift(1)\n",
    "imported_data[\"btc_close_shifted\"] = imported_data[\"btc_close\"].shift(1)\n",
    "imported_data[\"eth_close_shifted\"] = imported_data[\"eth_close\"].shift(1)\n",
    "imported_data = imported_data.dropna()\n",
    "# print(imported_data.head())\n",
    "# print(imported_data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the predictor variables from the response variable\n",
    "y = imported_data[\"arb_close\"]\n",
    "X = pd.DataFrame(imported_data, columns=[\"btc_close\", \"eth_close\", \"matic_close\"])\n",
    "X_shifted = pd.DataFrame(imported_data, columns=[\"btc_close_shifted\", \"eth_close_shifted\", \"matic_close_shifted\"])\n",
    "# print(imported_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_shifted_train, X_shifted_test, y_train, y_test = train_test_split(X_shifted, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression - unshifted: \n",
      "train_score:  0.8093944338091594\n",
      "test_score:  0.8784764159422679\n",
      "mse:  1.4297694926804144e-05\n",
      "Linear regression - shifted: \n",
      "train_score:  0.8020999571463565\n",
      "test_score:  0.850093554720059\n",
      "mse_shifted:  1.7637042544400532e-05\n"
     ]
    }
   ],
   "source": [
    "# Create a Linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg_model = LinearRegression()\n",
    "train_score = lin_reg_model.fit(X_train, y_train).score(X_train, y_train)\n",
    "test_score = lin_reg_model.fit(X_test, y_test).score(X_test, y_test)\n",
    "y_pred = lin_reg_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Linear regression - unshifted: \")\n",
    "print(\"train_score: \", train_score)\n",
    "print(\"test_score: \", test_score)\n",
    "print(\"mse: \", mse)\n",
    "lin_reg_model = LinearRegression()\n",
    "train_shifted_score = lin_reg_model.fit(X_shifted_train, y_train).score(X_shifted_train, y_train)\n",
    "test_shifted_score = lin_reg_model.fit(X_shifted_test, y_test).score(X_shifted_test, y_test)\n",
    "y_shifted_pred = lin_reg_model.predict(X_shifted_test)\n",
    "mse_shifted = mean_squared_error(y_test, y_shifted_pred)\n",
    "print(\"Linear regression - shifted: \")\n",
    "print(\"train_score: \", train_shifted_score)\n",
    "print(\"test_score: \", test_shifted_score)\n",
    "print(\"mse_shifted: \", mse_shifted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### -> The linear regression performs better without the 1-minute shift on Bitcoin, Ethereum, and Polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  0.0001 , mse:  2.8059886497948458e-05 , train_score:  0.7118744059628961 , test_score:  0.761504354866938\n",
      "alpha:  0.02 , mse:  8.306628950829137e-05 , train_score:  0.2727087261889618 , test_score:  0.29397617818097455\n",
      "alpha:  0.03 , mse:  0.00011277932598640406 , train_score:  0.03414345872919422 , test_score:  0.04142954709507196\n",
      "alpha:  0.04 , mse:  0.00011300181647846996 , train_score:  0.03359844345001983 , test_score:  0.039538484084353454\n",
      "alpha:  0.05 , mse:  0.00011323771771251175 , train_score:  0.032897709519653096 , test_score:  0.037533436166408474\n",
      "alpha:  0.06 , mse:  0.00011348702968852926 , train_score:  0.03204125693809445 , test_score:  0.035414403341238576\n",
      "alpha:  0.08 , mse:  0.00011402588586649005 , train_score:  0.02986119582140212 , test_score:  0.030834382969235574\n",
      "alpha:  0.1 , mse:  0.00011461838501235287 , train_score:  0.027058260099937503 , test_score:  0.025798422968340007\n",
      "alpha:  0.12 , mse:  0.00011526452712611798 , train_score:  0.02363244977370127 , test_score:  0.02030652333854932\n",
      "alpha:  0.15 , mse:  0.00011633432086158151 , train_score:  0.01732584440040774 , test_score:  0.011213787089693228\n",
      "alpha:  0.2 , mse:  0.00011838552526019851 , train_score:  0.0037004624210680293 , test_score:  -0.006220471469538635\n"
     ]
    }
   ],
   "source": [
    "# Create a Linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "alphas = [0.0001, 0.02, 0.03, 0.04, 0.05, 0.06, 0.08, 0.10, 0.12, 0.15, 0.20]\n",
    "for alpha_value in alphas:\n",
    "    lasso_model = Lasso(alpha=alpha_value)\n",
    "    lasso_model.fit(X_train, y_train)\n",
    "    y_pred = lasso_model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    train_score = lasso_model.score(X_train, y_train)\n",
    "    test_score = lasso_model.score(X_test, y_test)\n",
    "    print(\"alpha: \", alpha_value, \", mse: \", mse, \", train_score: \", train_score, \", test_score: \", test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### -> Lasso does not work here as the train and test scores are worse than that of linear regression, MSE is higher,\n",
    "##### and the best train and test scores come as alpha approaches 0, negating the penalty introduced by Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  0.0001 , mse:  1.4885088325767738e-05 , train_score:  0.8082108632406028 , test_score:  0.8734838523535675\n",
      "alpha:  0.02 , mse:  2.707537613304483e-05 , train_score:  0.7193083213147495 , test_score:  0.7698722231630213\n",
      "alpha:  0.03 , mse:  2.7384527104422265e-05 , train_score:  0.7169311143294905 , test_score:  0.7672445874322936\n",
      "alpha:  0.04 , mse:  2.7543614354417413e-05 , train_score:  0.7157070689013425 , test_score:  0.7658924217233264\n",
      "alpha:  0.05 , mse:  2.7640559496596625e-05 , train_score:  0.7149609384767721 , test_score:  0.7650684342767543\n",
      "alpha:  0.06 , mse:  2.770582494644377e-05 , train_score:  0.7144585553337044 , test_score:  0.764513709097544\n",
      "alpha:  0.08 , mse:  2.7788136500320703e-05 , train_score:  0.7138249186054201 , test_score:  0.7638141001684338\n",
      "alpha:  0.1 , mse:  2.7837922665278793e-05 , train_score:  0.7134416867223095 , test_score:  0.7633909415241089\n",
      "alpha:  0.12 , mse:  2.7871286201263824e-05 , train_score:  0.7131849166125541 , test_score:  0.7631073673892224\n",
      "alpha:  0.15 , mse:  2.79047957374581e-05 , train_score:  0.7129271141987041 , test_score:  0.7628225523222283\n",
      "alpha:  0.2 , mse:  2.7938466951486676e-05 , train_score:  0.7126682735599316 , test_score:  0.7625363630707946\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "alphas = [0.0001, 0.02, 0.03, 0.04, 0.05, 0.06, 0.08, 0.10, 0.12, 0.15, 0.20]\n",
    "for alpha_value in alphas:\n",
    "    ridge_model = Ridge(alpha=alpha_value)\n",
    "    ridge_model.fit(X_train, y_train)\n",
    "    y_pred = ridge_model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    train_score = ridge_model.score(X_train, y_train)\n",
    "    test_score = ridge_model.score(X_test, y_test)\n",
    "    print(\"alpha: \", alpha_value, \", mse: \", mse, \", train_score: \", train_score, \", test_score: \", test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### -> Ridge regression works here, but not as well as that of linear regression. The MSE is closer to that of linear reg but still higher,\n",
    "##### Still, the best train and test scores come as alpha approaches 0, negating the penalty introduced by Ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Develop the Linear Regresion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statsmodels.api as sm\n",
    "# X_constant = sm.add_constant(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = lin_reg_model.fit(X_train, y_train)\n",
    "test_score = lin_reg_model.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = lin_reg_model.coef_\n",
    "intercept = lin_reg_model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.79733951e-05  1.75434902e-03 -1.99618472e+00]\n",
      "-0.4788748553383557\n"
     ]
    }
   ],
   "source": [
    "# Coefficients are: \"btc_close\", \"eth_close\", \"matic_close\"\n",
    "print(coefficients)\n",
    "print(intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### arb_price = -0.478875 + (1.797339e-05 * btc_price) + (1.754349e-03 * eth_price) - (1.996184 * matic_price)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98590ff4fe04c8543246b2a01debd3de3c5ca9b666f43f1fa87d5110c692004c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
